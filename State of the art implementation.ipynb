{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>\n",
    "\n",
    "The goal of the exercise is twofold:\n",
    "- To provide an overview of the state of the art implementation of a convolutional neural network (in our case ResNet 50) including all of the elements discussed in the previous lectures and labs (data input pipeline considerations, NCCL implementation, etc.)\n",
    "- To Illustrate how this example can be used as a template for further neural network development. We will implement a new neural network, “Alexnet OWT” as described in https://arxiv.org/abs/1404.5997.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Horovod</h1>\n",
    "\n",
    "<h2>Rationale</h2>\n",
    "Historically, for all the reasons discussed in this class, training large scale jobs was technically challenging. One of the key factors affecting our ability to scale was communication which had a non-trivial impact on the overall training speed as illustrated below: \n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_HorovodRationale.png\"/>\n",
    "\n",
    "Especially TensorFlow, which relied heavily on the presence of parameter servers when used with Synchronous SGD was experiencing substantial communication bottlenecks. As you can see in the diagrams below, as you increase the number of processes participating in training, and therefore communication, communication requirement becomes higher. This can be partially addressed by increasing the number of parameter servers, what also adds substantial complexity to the overall system.\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_HorovodParameterService.png\"/>\n",
    "\n",
    "The development of NVLINK and adaptation of HPC like communication patterns and especially All Reduce algorithm was one of the key cornerstones that allowed to overcome this challenge. It not only substantially reduces the overall amount of communication but also removes the need for the parameter server which in certain scenarios was a communication bottleneck. The diagram below illustrates how gradient exchange is implemented using the All reduce algorithm.\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_HorovodAllReduce.png\"/>\n",
    "\n",
    "Hiding this communication and implementation complexity is the core goal of Horovod. In this lab we will see how to use Horovod for distributed training. Throughout this exercise it will become very clear that we are not participating in the implementation of the gradient exchange logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transforming single GPU code to Horovod multi GPU implementation</h2>\n",
    "\n",
    "As discussed in the section above, one of the key goals of Horovod was to simplify the complexity of writing efficient distributed software. Therefore, migrating your single GPU model to a large multi GPU or even multi node setup is straightforward. The key software changes that need to be introduced in your code are as follows:\n",
    "\n",
    "<ul>\n",
    "    <li><b>hvd.init()</b> initializes Horovod.</li>\n",
    "    <li><b>config.gpu_options.visible_device_list = str(hvd.local_rank())</b> assigns a GPU to each of the TensorFlow processes (this code needs to be slightly adjusted if you want to mix the data and model parallel implementation).</li>\n",
    "    <li><b>opt=hvd.DistributedOptimizer(opt)</b> wraps any regular TensorFlow optimizer with Horovod optimizer which takes care of averaging gradients using ring-all reduce.</li>\n",
    "    <li><b>hvd.BroadcastGlobalVariablesHook(0)</b> broadcasts variables from the first process to all other processes. This can be used together with the MonitoredTrainingSession or if it is not used (like in this example) it can be called directly via the hvd.broadcast_global_variables(0) operations instead.</li>\n",
    "</ul>\n",
    "\n",
    "With those software components in mind let us focus on code review of our distributed algorithm which will be accompanied by several simple code exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Our example</h2>\n",
    "\n",
    "Before we dive into the implementation detail let us execute the code we will be reviewing in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "[[54403,1],0]: A high-performance Open MPI point-to-point messaging module\n",
      "was unable to find any relevant network interfaces:\n",
      "\n",
      "Module: OpenFabrics (openib)\n",
      "  Host: 37e56af97b35\n",
      "\n",
      "Another transport will be used instead, although this may result in\n",
      "lower performance.\n",
      "\n",
      "NOTE: You can disable this warning by setting the MCA parameter\n",
      "btl_base_warn_component_unused to 0.\n",
      "--------------------------------------------------------------------------\n",
      "Cmd line args:\n",
      "  --model=resnet50\n",
      "  --data_dir=/dli/data/tfdata352p90per\n",
      "  --batch_size=48\n",
      "Num ranks:   2\n",
      "Num images:  1000\n",
      "Model:       resnet50\n",
      "Batch size:  48 per device\n",
      "             96 total\n",
      "Data format: NCHW\n",
      "Data type:   fp32\n",
      "Building training graph\n",
      "[37e56af97b35:00094] 1 more process has sent help message help-mpi-btl-base.txt / btl:no-nics\n",
      "[37e56af97b35:00094] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\n",
      "Creating session\n",
      "2019-03-11 06:28:51.064570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-03-11 06:28:51.064798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-03-11 06:28:51.066044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:1c.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.37GiB\n",
      "2019-03-11 06:28:51.066073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 1\n",
      "2019-03-11 06:28:51.066191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:1b.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.37GiB\n",
      "2019-03-11 06:28:51.066219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\n",
      "2019-03-11 06:28:51.379629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-03-11 06:28:51.379678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \n",
      "2019-03-11 06:28:51.379687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \n",
      "2019-03-11 06:28:51.380014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14884 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)\n",
      "2019-03-11 06:28:51.381850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-03-11 06:28:51.381882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      1 \n",
      "2019-03-11 06:28:51.381890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N \n",
      "2019-03-11 06:28:51.394754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14884 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)\n",
      "Initializing variables\n",
      "Pre-filling input pipeline\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss   LR\n",
      "     1     1     8.1  10.096 0.10000\n",
      "     2     1   125.5  12.922 0.10000\n",
      "     3     1   211.6  13.968 0.10000\n",
      "     4     1   252.5  14.122 0.10000\n",
      "     5     1   428.8  14.135 0.10000\n",
      "     6     1   431.4  14.189 0.10000\n",
      "     7     1   451.8  14.086 0.10000\n",
      "     8     1   397.6  13.883 0.10000\n",
      "     9     1   501.5  13.543 0.10000\n",
      "    10     1   508.4  13.003 0.10000\n",
      "    11     1   520.8  13.155 0.10000\n",
      "    12     2   501.1  13.390 0.10000\n",
      "    13     2   569.2  13.231 0.10000\n",
      "    14     2   466.2  13.044 0.10000\n",
      "    15     2   483.0  12.873 0.10000\n",
      "    16     2   492.7  12.904 0.10000\n",
      "    17     2   446.2  12.628 0.10000\n",
      "    18     2   524.4  12.423 0.10000\n",
      "    19     2   367.8  12.229 0.10000\n",
      "    20     2   485.1  12.054 0.10000\n",
      "    21     2   515.3  11.967 0.10000\n",
      "    22     3   520.4  11.798 0.10000\n",
      "    23     3   431.8  11.586 0.10000\n",
      "    24     3   459.1  11.456 0.10000\n",
      "    25     3   518.8  11.318 0.10000\n",
      "    26     3   486.9  11.258 0.10000\n",
      "    27     3   447.4  11.178 0.10000\n",
      "    28     3   504.6  11.081 0.10000\n",
      "    29     3   516.6  10.973 0.10000\n",
      "    30     3   521.3  11.001 0.10000\n",
      "    31     3   489.6  11.001 0.10000\n",
      "    32     3   507.6  10.935 0.10000\n",
      "    33     4   517.6  10.870 0.10000\n",
      "    34     4   470.9  10.908 0.10000\n",
      "    35     4   439.3  10.828 0.10000\n",
      "    36     4   425.4  10.782 0.10000\n",
      "    37     4   483.5  10.719 0.10000\n",
      "    38     4   575.0  10.674 0.10000\n",
      "    39     4   512.2  10.688 0.10000\n",
      "    40     4   350.2  10.776 0.10000\n",
      "    41     4   493.6  10.717 0.10000\n",
      "    42     4   544.0  10.673 0.10000\n",
      "    43     5   537.7  10.653 0.10000\n",
      "    44     5   437.5  10.607 0.10000\n",
      "    45     5   522.4  10.562 0.10000\n",
      "    46     5   420.6  10.520 0.10000\n",
      "    47     5   443.7  10.487 0.10000\n",
      "    48     5   448.2  10.464 0.10000\n",
      "    49     5   510.9  10.441 0.10000\n",
      "    50     5   408.6  10.413 0.10000\n",
      "----------------------------------------------------------------\n",
      "Images/sec: 482.0 +/- 8.9 (jitter = 44.8)\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! mpiexec --allow-run-as-root -np 2 python3 nvcnn_hvd_simplified.py \\\n",
    "                      --model=resnet50 \\\n",
    "                      --data_dir=/dli/data/tfdata352p90per \\\n",
    "                      --batch_size=48 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have noticed, we are not executing the code directly. Instead we are relying on <a href=\"https://en.wikipedia.org/wiki/Message_Passing_Interface\">mpiexec</a> to distribute the execution of our program (<a href=\"https://en.wikipedia.org/wiki/Message_Passing_Interface\">mpiexec</a> is a part of Message Passing Interface (MPI) which is a standard for writing portable parallel programmes. Horovod uses MPI as a mechanism to distribute its execution.). The syntax is straightforward. We pass the name of the program we want to execute, in our case <b>\"python nvcnn_hvd_simplified.py\"</b> followed by several program specific parameters. We also define number of GPUs we want to use.\n",
    "<br/><br/>\n",
    "To execute the code on more than one machine we would also provide a list of hosts which will be participating in the computation and increase the number of GPUs used.\n",
    "<br/>\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_HorovodDist.png\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Code structure</h2>\n",
    "\n",
    "Our code is composed of four major blocks:\n",
    "<ul>\n",
    "    <li><a href=\"../../../../edit/tasks/task2/task/GPUNetworkBuilder.py\">GPUNetworkBuilder.py</a> which contains the key building blocks for creation of Convolutional Neural Networks.</li>\n",
    "    <li><a href=\"../../../../edit/tasks/task2/task/ImagePreprocessor.py\">ImagePreprocessor.py</a> which defines a set of basic primitives for data loading, decoding and augmentation.</li>\n",
    "    <li><a href=\"../../../../edit/tasks/task2/task/FeedForwardTrainer.py\">FeedForwardTrainer.py</a> which defines the end to end training pipeline bringing together the key code components. This includes taking advantage of the ImagePreprocessor routines to build a multithreaded and asynchronous input pipeline but also definition of the training step and the optimization regime.</li>\n",
    "    <li>Model definition. In our case we will implement two models, hence two files, <a href=\"../../../../edit/tasks/task2/task/AlexNet.py\">AlexNet.py</a> and <a href=\"../../../../edit/tasks/task2/task/ResNet.py\">ResNet.py</a></li>\n",
    "</ul>\n",
    "\n",
    "The entire training functionality (taking advantage of the above mentioned files) is defined in <a href=\"../../../../edit/tasks/task2/task/nvcnn_hvd_simplified.py\">nvcnn_hvd_simplified.py</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GPUNetworkBuilder</h2>\n",
    "\n",
    "<a href=\"../../../../edit/tasks/task2/task/GPUNetworkBuilder.py\">GPUNetworkBuilder.py</a> is a very simple class that implements key building blocks of modern Convolutional Neural Networks. It implements operations such as pooling:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_PoolingLayer.png\" width=600/>\n",
    "\n",
    "or a wide range of activation functions:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_ActivateLayer.png\" width=600/>\n",
    "\n",
    "In order to use the functionality defined in the class, we need to create an instance of the class:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_GPUNetworkBuilder.png\"/>\n",
    "\n",
    "and then use it directly to define our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model definition files</h2>\n",
    "\n",
    "The <a href=\"../../../../edit/tasks/task2/task/GPUNetworkBuilder.py\">GPUNetworkBuilder.py</a>  is then used by the  <a href=\"../../../../edit/tasks/task2/task/AlexNet.py\">AlexNet.py</a> and <a href=\"../../../../edit/tasks/task2/task/ResNet.py\">ResNet.py</a> to define the shape of the models we will be training. For example it is used in <a href=\"../../../../edit/tasks/task2/task/AlexNet.py\">AlexNet.py</a> to define the shape of the AlexNet neural network:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_AlexNetInference.png\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Adding a new model</h2>\n",
    "\n",
    "In this part of the exercise we will extend the capability of our script by introducing a new model, AlexNet. As you have already seen during this exercise our source code is very modular so adding a new model is limited to:\n",
    "<ul>\n",
    "    <li>Defining our model through the inference function</li>\n",
    "    <li>Extending our command line interface to allow the user to select AlexNet as a model and pass model specific hyperparameters to the trainer.\n",
    "</ul>\n",
    "\n",
    "Let us look at those steps one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining the AlexNet model</h3>\n",
    "\n",
    "Since we have collected all of the key building blocks of CNN networks in previously discussed <a href=\"../../../../edit/tasks/task2/task/GPUNetworkBuilder.py\">GPUNetworkBuilder.py</a> creation of a new model (especially as simple as AlexNet) is straightforward. Because of the time constraints of our class we will not be building the model from scratch, instead we will integrate the model as defined in <a href=\"../../../../edit/tasks/task2/task/AlexNet.py\">AlexNet.py</a> to our program. The file <a href=\"../../../../edit/tasks/task2/task/AlexNet.py\">AlexNet.py</a> contains a single function that takes two parameters:\n",
    "<ul>\n",
    "    <li>Our network builder object</li>\n",
    "    <li>Input layer that we will use to deliver raw image data to our network</li>\n",
    "</ul>\n",
    "\n",
    "The function returns a computational graph defining the AlexNet model which we can then pass to our distributed optimization logic.\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_AlexNetInference.png\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Integration</h3>\n",
    "\n",
    "Let us now try to integrate the model defined above with the rest of our code. We will be working with the <b><a href=\"../../../../edit/tasks/task2/task/nvcnn_hvd_noAlexNet.py\">nvcnn_hvd_noAlexNet.py</a></b> file. If at any point you would like to inspect a working solution do refer to the <a href=\"../../../../edit/tasks/task2/task/nvcnn_hvd_simplified.py\">nvcnn_hvd_simplified.py</a> file.\n",
    "<br/><br/>\n",
    "First step is to import our model. Please identify a section in <a href=\"../../../../edit/tasks/task2/task/nvcnn_hvd_noAlexNet.py\">nvcnn_hvd_noAlexNet.py</a> where we are importing the ResNet model and follow the same structure to import the AlexNet model. E.g.:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_AlexNetImport.png\" width=600/>\n",
    "<br/><br/>\n",
    "Secondly we need to:\n",
    "<ul>\n",
    "    <li>Identify the section which is responsible for handling user input and define a conditional statement which will be executed when the user selects to execute the AlexNet network</li>\n",
    "    <li>In that section we need to set AlexNet as a model we are going to optimize</li>\n",
    "    <li>Finally we need to define model specific parameters. In this case the image dimensions and the learning rate.</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_AlexNetControll.png\" width=600/>\n",
    "\n",
    "<br/><br/>\n",
    "<b>Remember to save your changes!</b>\n",
    "<br/><br/>\n",
    "\n",
    "Once the changes are saved executing the code is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "[[53452,1],0]: A high-performance Open MPI point-to-point messaging module\n",
      "was unable to find any relevant network interfaces:\n",
      "\n",
      "Module: OpenFabrics (openib)\n",
      "  Host: 37e56af97b35\n",
      "\n",
      "Another transport will be used instead, although this may result in\n",
      "lower performance.\n",
      "\n",
      "NOTE: You can disable this warning by setting the MCA parameter\n",
      "btl_base_warn_component_unused to 0.\n",
      "--------------------------------------------------------------------------\n",
      "Cmd line args:\n",
      "  --model=alexnet\n",
      "  --data_dir=/dli/data/tfdata352p90per\n",
      "  --batch_size=48\n",
      "Num ranks:   2\n",
      "Num images:  1000\n",
      "Model:       alexnet\n",
      "Batch size:  48 per device\n",
      "             96 total\n",
      "Data format: NCHW\n",
      "Data type:   fp32\n",
      "Traceback (most recent call last):\n",
      "  File \"nvcnn_hvd_noAlexNet.py\", line 302, in <module>\n",
      "    main()\n",
      "  File \"nvcnn_hvd_noAlexNet.py\", line 142, in main\n",
      "    raise ValueError(\"Invalid model type: %s\" % model_name)\n",
      "ValueError: Invalid model type: alexnet\n",
      "Traceback (most recent call last):\n",
      "  File \"nvcnn_hvd_noAlexNet.py\", line 302, in <module>\n",
      "    main()\n",
      "  File \"nvcnn_hvd_noAlexNet.py\", line 142, in main\n",
      "    raise ValueError(\"Invalid model type: %s\" % model_name)\n",
      "ValueError: Invalid model type: alexnet\n",
      "-------------------------------------------------------\n",
      "Primary job  terminated normally, but 1 process returned\n",
      "a non-zero exit code. Per user-direction, the job has been aborted.\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "mpiexec detected that one or more processes exited with non-zero status, thus causing\n",
      "the job to be terminated. The first process to do so was:\n",
      "\n",
      "  Process name: [[53452,1],1]\n",
      "  Exit code:    1\n",
      "--------------------------------------------------------------------------\n",
      "[37e56af97b35:01041] 1 more process has sent help message help-mpi-btl-base.txt / btl:no-nics\n",
      "[37e56af97b35:01041] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\n"
     ]
    }
   ],
   "source": [
    "! mpiexec --allow-run-as-root -np 2 python3 nvcnn_hvd_noAlexNet.py \\\n",
    "                      --model=alexnet \\\n",
    "                      --data_dir=/dli/data/tfdata352p90per \\\n",
    "                      --batch_size=48 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>If you have any problems with the code above feel free to execute the working version of the code (which you can inspect <a href=\"../../../../edit/tasks/task2/task/nvcnn_hvd_simplified.py\">here</a>).</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mpiexec --allow-run-as-root -np 2 python3 nvcnn_hvd_simplified.py \\\n",
    "                      --model=alexnet \\\n",
    "                      --data_dir=/dli/data/tfdata352p90per \\\n",
    "                      --batch_size=48 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Input pipeline</h2>\n",
    "\n",
    "The <a href=\"../../../../edit/tasks/task2/task/ImagePreprocessor.py\">ImagePreprocessor.py</a> implements a collection of routines that will be further used to implement a multithreaded and asynchronous input pipeline. It implements operations such as input decoding:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_DecodeJPEG.png\" width=400/>\n",
    "\n",
    "Wide range of data augmentation operations:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_Augmentation.png\" width=500/>\n",
    "\n",
    "As well as a multithreaded data loading process:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_ParallelLoad.png\" width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of the code structure let us change the behavior of the data input pipeline by:\n",
    "<ul>\n",
    "    <li>Changing the JPEG decoder used. This will help you identify the portions of code responsible for key loading stages so that you learn how to replace the data type or data structure in your day to day deep learning projects</li>\n",
    "    <li>Extending the data augmentation pipeline. Again this will teach you how to systematically approach the augmentation process allowing you to apply this skill in project.</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data loading logic</h3>\n",
    "\n",
    "\n",
    "The data loading logic is composed of three parts:\n",
    "<ul>\n",
    "    <li>Logic responsible for loading the files from the file system. Please note that we are not using python or OpenCV specific data manipulation logic. Instead we are using highly parallel data manipulation logic that comes together with TensorFLow. In our case we will be spawning 64 threads to support the process. <img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_ParallelLoad.png\" width=400/></li>\n",
    "    <li>Logic de-serializing our data. As you will remember from the lecture we are not working on the image data directly. Instead in this case we have stored them in a TensorFlow specific data storage format called TFRecord. The function listed below is responsible for reserializing this data representation and extracting the raw image data. <img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_DeserializeJPEG.png\" width=400/></li>\n",
    "    <li>In our case the data is stored in JPEG format (this is not always possible though as lossy compression introduces changes to the data unavoidably removing information from our dataset). The function below is responsible for its efficient decode. <img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_JPEGDecode.png\" width=400/></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find the above logic responsible for JPEG decoding in <a href=\"../../../../edit/tasks/task2/task/ImagePreprocessor.py\">ImagePreprocessor.py</a> and change the decoder used from \"INTEGER_FAST\" to \"INTEGER_ACCURATE\". Once you have made the suggested changes remember to save the file and execute the training on AlexNet network again to see the implications of the change made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "[[53362,1],1]: A high-performance Open MPI point-to-point messaging module\n",
      "was unable to find any relevant network interfaces:\n",
      "\n",
      "Module: OpenFabrics (openib)\n",
      "  Host: 37e56af97b35\n",
      "\n",
      "Another transport will be used instead, although this may result in\n",
      "lower performance.\n",
      "\n",
      "NOTE: You can disable this warning by setting the MCA parameter\n",
      "btl_base_warn_component_unused to 0.\n",
      "--------------------------------------------------------------------------\n",
      "Cmd line args:\n",
      "  --model=alexnet\n",
      "  --data_dir=/dli/data/tfdata352p90per\n",
      "  --batch_size=48\n",
      "Num ranks:   2\n",
      "Num images:  1000\n",
      "Model:       alexnet\n",
      "Batch size:  48 per device\n",
      "             96 total\n",
      "Data format: NCHW\n",
      "Data type:   fp32\n",
      "Building training graph\n",
      "Creating session\n",
      "[37e56af97b35:01199] 1 more process has sent help message help-mpi-btl-base.txt / btl:no-nics\n",
      "[37e56af97b35:01199] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\n",
      "2019-03-11 07:03:59.737563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-03-11 07:03:59.737798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-03-11 07:03:59.739044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:1b.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.37GiB\n",
      "2019-03-11 07:03:59.739071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\n",
      "2019-03-11 07:03:59.739198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:1c.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.37GiB\n",
      "2019-03-11 07:03:59.739224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 1\n",
      "2019-03-11 07:04:00.051912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-03-11 07:04:00.051962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \n",
      "2019-03-11 07:04:00.051971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \n",
      "2019-03-11 07:04:00.052292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14884 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)\n",
      "2019-03-11 07:04:00.052556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-03-11 07:04:00.052589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      1 \n",
      "2019-03-11 07:04:00.052597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N \n",
      "2019-03-11 07:04:00.066910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14884 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)\n",
      "Initializing variables\n",
      "Pre-filling input pipeline\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss   LR\n",
      "     1     1    37.7   7.525 0.03000\n",
      "     2     1   446.4   7.529 0.03000\n",
      "     3     1   513.9   7.529 0.03000\n",
      "     4     1   397.0   7.528 0.03000\n",
      "     5     1   628.1   7.529 0.03000\n",
      "     6     1   628.9   7.526 0.03000\n",
      "     7     1   621.7   7.528 0.03000\n",
      "     8     1   518.0   7.527 0.03000\n",
      "     9     1   677.5   7.528 0.03000\n",
      "    10     1   651.1   7.531 0.03000\n",
      "    11     1   634.8   7.528 0.03000\n",
      "    12     2   591.4   7.527 0.03000\n",
      "    13     2   722.3   7.530 0.03000\n",
      "    14     2   728.1   7.530 0.03000\n",
      "    15     2   631.1   7.530 0.03000\n",
      "    16     2   618.5   7.531 0.03000\n",
      "    17     2   482.3   7.532 0.03000\n",
      "    18     2   804.7   7.532 0.03000\n",
      "    19     2   480.0   7.533 0.03000\n",
      "    20     2   647.5   7.533 0.03000\n",
      "    21     2   525.0   7.532 0.03000\n",
      "    22     3   642.7   7.531 0.03000\n",
      "    23     3   659.7   7.531 0.03000\n",
      "    24     3   676.0   7.529 0.03000\n",
      "    25     3   688.7   7.528 0.03000\n",
      "    26     3   715.3   7.527 0.03000\n",
      "    27     3   537.0   7.527 0.03000\n",
      "    28     3   723.7   7.526 0.03000\n",
      "    29     3   728.7   7.525 0.03000\n",
      "    30     3   709.2   7.526 0.03000\n",
      "    31     3   651.7   7.527 0.03000\n",
      "    32     3   646.8   7.526 0.03000\n",
      "    33     4   733.9   7.526 0.03000\n",
      "    34     4   652.6   7.526 0.03000\n",
      "    35     4   720.7   7.527 0.03000\n",
      "    36     4   696.9   7.526 0.03000\n",
      "    37     4   675.8   7.528 0.03000\n",
      "    38     4   736.3   7.527 0.03000\n",
      "    39     4   500.5   7.527 0.03000\n",
      "    40     4   530.8   7.528 0.03000\n",
      "    41     4   617.2   7.528 0.03000\n",
      "    42     4   613.4   7.528 0.03000\n",
      "    43     5   522.2   7.527 0.03000\n",
      "    44     5   565.4   7.527 0.03000\n",
      "    45     5   654.8   7.527 0.03000\n",
      "    46     5   709.8   7.527 0.03000\n",
      "    47     5   560.3   7.527 0.03000\n",
      "    48     5   755.8   7.527 0.03000\n",
      "    49     5   784.0   7.527 0.03000\n",
      "    50     5   693.5   7.528 0.03000\n",
      "----------------------------------------------------------------\n",
      "Images/sec: 654.3 +/- 14.3 (jitter = 76.7)\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! mpiexec --allow-run-as-root -np 2 python3 nvcnn_hvd_simplified.py \\\n",
    "                      --model=alexnet \\\n",
    "                      --data_dir=/dli/data/tfdata352p90per \\\n",
    "                      --batch_size=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have implemented a more costly JPEG decoding algorithm and our neural network is CPU compute bound we have observed a degradation in overall training performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Augmentation logic</h3>\n",
    "\n",
    "Our example implements the data decoding and augmentation logic in the following function:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_PreprocessJPEG.png\" width=500/>\n",
    "\n",
    "As you can see augmentation is composed of multiple image transformations. For example, the code snippet below illustrates logic used for color distortion:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_Augmentation.png\" width=500/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us introduce an additional augmentation step in <a href=\"../../../../edit/tasks/task2/task/ImagePreprocessor.py\">ImagePreprocessor.py</a>.\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_RandomFlip.png\" width=400/>\n",
    "\n",
    "Once you have introduced the changes and saved the file execute the below script again. Did you observe a further decrease in training performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mpiexec --allow-run-as-root -np 2 python3 nvcnn_hvd_noAlexNet.py \\\n",
    "                      --model=alexnet \\\n",
    "                      --data_dir=/dli/data/tfdata352p90per \\\n",
    "                      --batch_size=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training logic</h2>\n",
    "\n",
    "The <a href=\"../../../../edit/tasks/task2/task/FeedForwardTrainer.py\">FeedForwardTrainer.py</a> implements the core of our training logic. It implements the training step function which we will loop through in our main code:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_TrainingStep.png\" width = 300/>\n",
    "\n",
    "Now that we have all our building blocks defined the training step function becomes straightforward. We start by assembling our input pipeline:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_InputPipeline.png\" width = 400/>\n",
    "\n",
    "We define the loss function by using the model selected (so in our case either AlexNet or ResNet50 inference function):\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_LossFunction.png\" width = 400/>\n",
    "\n",
    "We define the optimizer that we want to use and pass it to Horovod so that it can be distributed across the cluster:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_DistributedOptimiser.png\" width = 400/>\n",
    "\n",
    "We also implement the logic required to synchronize the gradients across all GPUs:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_syncHorovod.png\" width = 400/>\n",
    "\n",
    "We bring everything together and build our computational graph:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_TrainingGraph.png\" width=400/>\n",
    "\n",
    "And execute it in a training loop:\n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/training/images/C-MG-01-V1_task2_img_TrainingLoop.png\" width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we have demonstrated the synchronization logic, but we have not seen it being called anywhere in the code. Please find the call to the sync() function depicted above in <a href=\"../../../../edit/tasks/task2/task/nvcnn_hvd_simplified.py\">nvcnn_hvd_simplified.py</a>. Why is it outside of the training loop? How does this approach further simplify the implementation? Discuss it with the trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Summary</h2>\n",
    "\n",
    "As discussed at the beginning of class, Horovod allows us to ignore all the implementation detail related to distribution of our model including engineering related to model assignment to the GPU and communication. To distribute the code, we only had to implement the model and use Horovod specific optimizer and synchronization routines. All the remaining code is identical to a single GPU implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
